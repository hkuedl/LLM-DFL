{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1fd423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import warnings\n",
    "from utils import *\n",
    "from torch import nn\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from data_loader import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from http import HTTPStatus\n",
    "import dashscope\n",
    "from dashscope import Generation\n",
    "import json\n",
    "# import openai\n",
    "from openai import OpenAI\n",
    "from deepseek import DeepSeekClient\n",
    "import os\n",
    "from train import *\n",
    "import pickle\n",
    "from together import Together\n",
    "from openai import OpenAI\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#set deepseek and openai API keys\n",
    "\n",
    "\n",
    "\n",
    "dashscope.api_key = 'YOUR KEY'\n",
    "DEEPSEEK_API_KEY = 'YOUR KEY'\n",
    "OPENAI_API_KEY = 'YOUR KEY'\n",
    "LLAMA_API_KEY= 'YOUR KEY'\n",
    "#openai.api_key = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7139344",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser_train = argparse.ArgumentParser()\n",
    "parser_train.add_argument('--seq_len', type=int, default=24*7)\n",
    "parser_train.add_argument('--pred_len', type=int, default=24)\n",
    "parser_train.add_argument('--label_len', type=int, default=0)\n",
    "parser_train.add_argument('--train_length', type=int, default=17376)\n",
    "parser_train.add_argument('--target', type=str, default='target')\n",
    "parser_train.add_argument('--scale', type=bool, default=True)\n",
    "parser_train.add_argument('--inverse', type=bool, default=True)\n",
    "parser_train.add_argument('--num_epochs', type=int, default=1000)\n",
    "parser_train.add_argument('--mode', type=str, default='parameter')\n",
    "parser_train.add_argument('--quantiles', type=list, default=[0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95])\n",
    "parser_train.add_argument('--lr', type=float, default=1e-4)\n",
    "parser_train.add_argument('--patience', type=int, default=5)\n",
    "parser_train.add_argument('--hidden_layers', type=list, default=[128,128,128])\n",
    "parser_train.add_argument('--e2e_num_epochs', type=int, default=5)\n",
    "parser_train.add_argument('--e2e_ft_lr', type=float, default=1e-6)\n",
    "parser_train.add_argument('--e2e_lr', type=float, default=1e-7)#1e-7\n",
    "parser_train.add_argument('--ft_lr', type=float, default=1e-4)\n",
    "parser_train.add_argument('--batch_size', type=int, default=16)\n",
    "parser_train.add_argument('--device', type=str, default='cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "parser_train.add_argument('--epsion_p', type=float, default=1e1)\n",
    "parser_train.add_argument('--epsion_l', type=float, default=1e1)\n",
    "parser_train.add_argument('--metric_list', type=list, default=['pinball_loss','winkler_score_0.1','MAE','RMSE'])\n",
    "\n",
    "\n",
    "parser_train.add_argument('--N_g', type=int, default=3)\n",
    "parser_train.add_argument('--T', type=int, default=24)\n",
    "parser_train.add_argument('--N', type=int, default=25)\n",
    "parser_train.add_argument('--x_max', type=int, default=[1500,1800,2000])\n",
    "parser_train.add_argument('--x_min', type=int, default=[0,0,0])\n",
    "parser_train.add_argument('--z_pos_max', type=list, default=[500,700,800])\n",
    "parser_train.add_argument('--z_neg_max', type=list, default=[500,700,800])\n",
    "parser_train.add_argument('--z_pos_min', type=int, default=0)\n",
    "parser_train.add_argument('--z_neg_min', type=int, default=0)\n",
    "parser_train.add_argument('--r_neg', type=int, default=[800,800,500])\n",
    "parser_train.add_argument('--r_pos', type=int, default=[800,800,500])\n",
    "parser_train.add_argument('--alpha', type=list, default=[0.03 for i in range(24)]+[0.028 for i in range(24)]+[0.032 for i in range(24)])\n",
    "parser_train.add_argument('--alpha_pos', type=list, default=[0.02 for i in range(24)]+[0.018 for i in range(24)]+[0.022 for i in range(24)])\n",
    "parser_train.add_argument('--alpha_neg', type=list, default=[0.01 for i in range(24)]+[0.009 for i in range(24)]+[0.011 for i in range(24)])\n",
    "\n",
    "parser_train.add_argument('--rho_z_pos', type=list, default=[0.05 for i in range(24)]+[0.045 for i in range(24)]+[0.055 for i in range(24)])\n",
    "parser_train.add_argument('--rho_z_neg', type=list, default=[0.01 for i in range(24)]+[0.008 for i in range(24)]+[0.012 for i in range(24)])\n",
    "\n",
    "parser_train.add_argument('--rho_r_pos', type=list, default=[0.1 for i in range(24)])\n",
    "parser_train.add_argument('--rho_r_neg', type=list, default=[0.05 for i in range(24)])\n",
    "\n",
    "parser_train.add_argument('--price_ratio_large', type=float, default=2.5)\n",
    "parser_train.add_argument('--price_ratio_small', type=float, default=0.8)\n",
    "parser_train.add_argument('--flag_dynamic_price', type=bool, default=False)\n",
    "parser_train.add_argument('--flag_dynamic_mode', type=int, default=0)\n",
    "parser_train.add_argument('--upper_quantiles', type=float, default=0.95)\n",
    "parser_train.add_argument('--lower_quantiles', type=float, default=0.05)\n",
    "parser_train.add_argument('--epsion', type=float, default=1)\n",
    "parser_train.add_argument('--LLM_type', type=str, default='Deepseek') #'euclidean' 'manhattan'\n",
    "args = parser_train.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6bc623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/GEF_data/data(3 year).csv\n",
      "['month', 'weekday', 'hour', 'temp', 'load_1_day_before', 'load_2_day_before', 'load_3_day_before', 'load_4_day_before', 'load_5_day_before', 'load_6_day_before', 'load_7_day_before']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693, 24, 11) (693, 24) (29, 24, 11) (29, 24)\n",
      "(358, 24, 11)\n",
      "(358, 24)\n",
      "../Data/GEF_data/data(3 year).csv\n",
      "['month', 'weekday', 'hour', 'temp', 'load_1_day_before', 'load_2_day_before', 'load_3_day_before', 'load_4_day_before', 'load_5_day_before', 'load_6_day_before', 'load_7_day_before']\n",
      "(693, 24, 11) (693, 24) (29, 24, 11) (29, 24)\n",
      "(335, 24, 11)\n",
      "(335, 24)\n",
      "../Data/GEF_data/data(3 year).csv\n",
      "['month', 'weekday', 'hour', 'temp', 'load_1_day_before', 'load_2_day_before', 'load_3_day_before', 'load_4_day_before', 'load_5_day_before', 'load_6_day_before', 'load_7_day_before']\n",
      "(693, 24, 11) (693, 24) (29, 24, 11) (29, 24)\n",
      "(29, 24, 11)\n",
      "(29, 24)\n"
     ]
    }
   ],
   "source": [
    "train_load_data,train_load_loader=get_load_data(args,flag='train')\n",
    "val_load_data,val_load_loader=get_load_data(args,flag='val')\n",
    "test_load_data,test_load_loader=get_load_data(args,flag='test')\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986e6d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 11)\n",
      "(29, 96)\n",
      "(8592, 11)\n",
      "(358, 96)\n",
      "(8040, 11)\n",
      "(335, 96)\n"
     ]
    }
   ],
   "source": [
    "history_X_test = []\n",
    "history_X_train = []\n",
    "history_X_val = []\n",
    "\n",
    "X_test=train_load_data.inverse_transform_X(test_load_data.X)\n",
    "X_train=train_load_data.inverse_transform_X(train_load_data.X)\n",
    "X_val=train_load_data.inverse_transform_X(val_load_data.X)\n",
    "\n",
    "for i in range(len(X_test)//24):\n",
    "    temp=X_test[i*24:(i+1)*24:,4:8]\n",
    "    history_X_test.append(np.concatenate([temp[:, i] for i in range(temp.shape[1]-1, -1, -1)]))\n",
    "\n",
    "for i in range(len(X_train)//24):\n",
    "    temp=X_train[i*24:(i+1)*24:,4:8]\n",
    "    history_X_train.append(np.concatenate([temp[:, i] for i in range(temp.shape[1]-1, -1, -1)]))\n",
    "\n",
    "for i in range(len(X_val)//24):\n",
    "    temp=X_val[i*24:(i+1)*24:,4:8]\n",
    "    history_X_val.append(np.concatenate([temp[:, i] for i in range(temp.shape[1]-1, -1, -1)]))\n",
    "\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(history_X_test))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(history_X_train))\n",
    "print(np.shape(X_val))\n",
    "print(np.shape(history_X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e644a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 0.7720027593049136\n",
      "Epoch [1/1000] Train Loss: 0.7720 Val Loss: 0.7282\n",
      "Epoch [2/1000] Train Loss: 0.6608 Val Loss: 0.6028\n",
      "Epoch [3/1000] Train Loss: 0.5162 Val Loss: 0.4283\n",
      "Epoch [4/1000] Train Loss: 0.3167 Val Loss: 0.1953\n",
      "Epoch [5/1000] Train Loss: 0.0609 Val Loss: -0.0990\n",
      "Epoch [6/1000] Train Loss: -0.2893 Val Loss: -0.4934\n",
      "Epoch [7/1000] Train Loss: -0.6568 Val Loss: -0.7070\n",
      "Epoch [8/1000] Train Loss: -0.8241 Val Loss: -0.7556\n",
      "Epoch [9/1000] Train Loss: -0.8528 Val Loss: -0.7997\n",
      "Epoch [10/1000] Train Loss: -0.9192 Val Loss: -0.8057\n",
      "Epoch 10, Train Loss: -0.9492454610087655\n",
      "Epoch [11/1000] Train Loss: -0.9492 Val Loss: -0.8482\n",
      "Epoch [12/1000] Train Loss: -0.9866 Val Loss: -0.8666\n",
      "Epoch [13/1000] Train Loss: -1.0303 Val Loss: -0.8967\n",
      "Epoch [14/1000] Train Loss: -1.0546 Val Loss: -0.9234\n",
      "Epoch [15/1000] Train Loss: -1.0968 Val Loss: -0.9260\n",
      "Epoch [16/1000] Train Loss: -1.1024 Val Loss: -0.9781\n",
      "Epoch [17/1000] Train Loss: -1.1692 Val Loss: -0.9796\n",
      "Epoch [18/1000] Train Loss: -1.1937 Val Loss: -0.9987\n",
      "Epoch [19/1000] Train Loss: -1.1887 Val Loss: -1.0473\n",
      "Epoch [20/1000] Train Loss: -1.2229 Val Loss: -1.0972\n",
      "Epoch 20, Train Loss: -1.2538707310503179\n",
      "Epoch [21/1000] Train Loss: -1.2539 Val Loss: -1.0604\n",
      "Epoch [22/1000] Train Loss: -1.2874 Val Loss: -1.1148\n",
      "Epoch [23/1000] Train Loss: -1.2843 Val Loss: -1.1552\n",
      "Epoch [24/1000] Train Loss: -1.3148 Val Loss: -1.1873\n",
      "Epoch [25/1000] Train Loss: -1.3383 Val Loss: -1.1830\n",
      "Epoch [26/1000] Train Loss: -1.3601 Val Loss: -1.2289\n",
      "Epoch [27/1000] Train Loss: -1.3830 Val Loss: -1.2421\n",
      "Epoch [28/1000] Train Loss: -1.4146 Val Loss: -1.2101\n",
      "Epoch [29/1000] Train Loss: -1.4258 Val Loss: -1.2657\n",
      "Epoch [30/1000] Train Loss: -1.4445 Val Loss: -1.2961\n",
      "Epoch 30, Train Loss: -1.4473995674740185\n",
      "Epoch [31/1000] Train Loss: -1.4474 Val Loss: -1.2909\n",
      "Epoch [32/1000] Train Loss: -1.4768 Val Loss: -1.3218\n",
      "Epoch [33/1000] Train Loss: -1.4880 Val Loss: -1.3398\n",
      "Epoch [34/1000] Train Loss: -1.4591 Val Loss: -1.3469\n",
      "Epoch [35/1000] Train Loss: -1.5019 Val Loss: -1.3596\n",
      "Epoch [36/1000] Train Loss: -1.5192 Val Loss: -1.3711\n",
      "Epoch [37/1000] Train Loss: -1.5327 Val Loss: -1.3726\n",
      "Epoch [38/1000] Train Loss: -1.4977 Val Loss: -1.3818\n",
      "Epoch [39/1000] Train Loss: -1.5311 Val Loss: -1.3909\n",
      "Epoch [40/1000] Train Loss: -1.5506 Val Loss: -1.4083\n",
      "Epoch 40, Train Loss: -1.5519237843426792\n",
      "Epoch [41/1000] Train Loss: -1.5519 Val Loss: -1.4110\n",
      "Epoch [42/1000] Train Loss: -1.5563 Val Loss: -1.4167\n",
      "Epoch [43/1000] Train Loss: -1.5570 Val Loss: -1.4203\n",
      "Epoch [44/1000] Train Loss: -1.5693 Val Loss: -1.4411\n",
      "Epoch [45/1000] Train Loss: -1.5835 Val Loss: -1.4392\n",
      "Epoch [46/1000] Train Loss: -1.5904 Val Loss: -1.4460\n",
      "Epoch [47/1000] Train Loss: -1.6053 Val Loss: -1.4051\n",
      "Epoch [48/1000] Train Loss: -1.5893 Val Loss: -1.4012\n",
      "Epoch [49/1000] Train Loss: -1.5705 Val Loss: -1.4710\n",
      "Epoch [50/1000] Train Loss: -1.6114 Val Loss: -1.4666\n",
      "Epoch 50, Train Loss: -1.6011461832306602\n",
      "Epoch [51/1000] Train Loss: -1.6011 Val Loss: -1.4526\n",
      "Epoch [52/1000] Train Loss: -1.6120 Val Loss: -1.4651\n",
      "Epoch [53/1000] Train Loss: -1.6049 Val Loss: -1.4852\n",
      "Epoch [54/1000] Train Loss: -1.5886 Val Loss: -1.4876\n",
      "Epoch [55/1000] Train Loss: -1.6199 Val Loss: -1.4990\n",
      "Epoch [56/1000] Train Loss: -1.6389 Val Loss: -1.4870\n",
      "Epoch [57/1000] Train Loss: -1.6325 Val Loss: -1.4847\n",
      "Epoch [58/1000] Train Loss: -1.6372 Val Loss: -1.4984\n",
      "Epoch [59/1000] Train Loss: -1.6304 Val Loss: -1.4970\n",
      "Epoch [60/1000] Train Loss: -1.6497 Val Loss: -1.4599\n",
      "Early stopping at epoch 60\n",
      "-1.4990043083117122\n"
     ]
    }
   ],
   "source": [
    "input_size=train_load_data.X.shape[-1]\n",
    "output_size=24\n",
    "set_seed(42)\n",
    "\n",
    "layer_sizes=[128,128,128]\n",
    "\n",
    "input_size=train_load_data.X.shape[-1]\n",
    "output_size=1\n",
    "model_load=ANN_gaussian(input_size=input_size, hidden_layers=layer_sizes, output_size=output_size).to(device)\n",
    "train_parameter(args, model_load, train_load_loader, val_load_loader,dir_best_model='../Model/best_ann_load.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf25841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pinball_loss(y_true, y_pred, quantiles):\n",
    "    if not isinstance(y_true, np.ndarray):\n",
    "        y_true = np.array(y_true)\n",
    "    \n",
    "    y_true_expanded = np.expand_dims(y_true, axis=-1)\n",
    "    errors = y_true_expanded - y_pred\n",
    "    q_array = np.array(quantiles, dtype=y_pred.dtype)\n",
    "\n",
    "    losses = np.maximum((q_array - 1) * errors, q_array * errors)\n",
    "    loss = np.mean(losses, axis=0).sum()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def quantile_normal_inverse_transform(mu, sigma, quantiles):\n",
    "    if isinstance(mu, torch.Tensor):\n",
    "        z = torch.tensor(quantiles, device=mu.device, dtype=mu.dtype)\n",
    "        z_scores = torch.distributions.Normal(0, 1).icdf(z)  # shape [len(quantiles)]\n",
    "        z_scores = z_scores.view(1, 1, -1)\n",
    "        y_quantiles = mu.unsqueeze(-1) + sigma.unsqueeze(-1) * z_scores\n",
    "    elif isinstance(mu, np.ndarray):\n",
    "        z = norm.ppf(quantiles)  # shape [len(quantiles)]\n",
    "        z_scores = z.reshape(1, 1, -1)\n",
    "        y_quantiles = mu[:, :, np.newaxis] + sigma[:, :, np.newaxis] * z_scores\n",
    "    \n",
    "    return y_quantiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "453869fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.990060389727 0.04054062257193172 174.52570138295076\n",
      "32601.732230395588\n"
     ]
    }
   ],
   "source": [
    "test_input=torch.tensor(test_load_data.X).to(device).float()\n",
    "test_pred_mu_nor, test_pred_var_nor = model_load(test_input)\n",
    "test_pred_mu=test_load_data.scaler_y.inverse_transform(test_pred_mu_nor.detach().cpu().numpy())\n",
    "test_pred_var=test_pred_var_nor.detach().cpu().numpy()*test_load_data.scaler_y.scale_\n",
    "test_actual_nor=test_load_data.y\n",
    "test_actual=test_load_data.scaler_y.inverse_transform(test_actual_nor)\n",
    "\n",
    "print(MAE(test_actual, test_pred_mu),MAPE(test_actual, test_pred_mu),RMSE(test_actual, test_pred_mu))\n",
    "\n",
    "quantiles=args.quantiles\n",
    "test_quantiles=quantile_normal_inverse_transform(test_pred_mu, test_pred_var, quantiles)\n",
    "print(pinball_loss(test_actual, test_quantiles, quantiles))\n",
    "\n",
    "val_input=torch.tensor(val_load_data.X).to(device).float()\n",
    "val_pred_mu_nor, val_pred_var_nor = model_load(val_input)\n",
    "val_pred_mu=val_load_data.scaler_y.inverse_transform(val_pred_mu_nor.detach().cpu().numpy())\n",
    "val_pred_var=val_pred_var_nor.detach().cpu().numpy()*val_load_data.scaler_y.scale_\n",
    "val_actual_nor=val_load_data.y\n",
    "val_actual=val_load_data.scaler_y.inverse_transform(val_actual_nor)\n",
    "\n",
    "train_input=torch.tensor(train_load_data.X).to(device).float()\n",
    "train_pred_mu_nor, train_pred_var_nor = model_load(train_input)\n",
    "train_pred_mu=train_load_data.scaler_y.inverse_transform(train_pred_mu_nor.detach().cpu().numpy())\n",
    "train_pred_var=train_pred_var_nor.detach().cpu().numpy()*train_load_data.scaler_y.scale_\n",
    "train_actual_nor=train_load_data.y\n",
    "train_actual=train_load_data.scaler_y.inverse_transform(train_actual_nor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b14a39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data is not shuffled\n",
      "Test data is not shuffled\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2026-08-26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cost over 30 runs: 3028.48773274922\n"
     ]
    }
   ],
   "source": [
    "combined_train_data,combined_train_loader,combined_val_data,combined_val_loader,combined_test_data,combined_test_loader,combined_fine_tune_data,combined_fine_tune_loader = obtain_price(args,train_load_data,val_load_data,test_load_data)\n",
    "\n",
    "data_iter = iter(combined_test_loader)\n",
    "input_load_test, labels_load_test, alpha_test, alpha_z_test, rho_z_test, rho_r_test = next(data_iter)\n",
    "\n",
    "alpha_sample=alpha_test[0,:].detach().cpu().numpy()\n",
    "alpha_z_sample=alpha_z_test[0,:].detach().cpu().numpy()\n",
    "rho_z_sample=rho_z_test[0,:].detach().cpu().numpy()\n",
    "rho_r_sample=rho_r_test[0,:].detach().cpu().numpy()\n",
    "\n",
    "set_seed(42)\n",
    "cost_list=[]\n",
    "optimization_module = Combined_SO_dispatch_GRB(args, alpha_sample, alpha_z_sample, rho_z_sample, rho_r_sample)\n",
    "# solution_DA_grb, cost_DA_grb, cost_DA_grb_value=optimization_module.forward(test_pred_mu[0],test_pred_var[0],test_actual[0])\n",
    "for i in range(29):\n",
    "    _,_,cost=optimization_module.forward(test_pred_mu[i],test_pred_var[i],test_actual[i])\n",
    "    cost_list.append(cost)\n",
    "print('Average cost over 30 runs:', np.mean(cost_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "789fc6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cost over 30 runs (OptNet): 3028.487733174566\n"
     ]
    }
   ],
   "source": [
    "SO_layer_cvxpy = DA_dispatch_SO_cvxpy(args)\n",
    "intra_dispatch_cvxpy = RT_dispatch_cvxpy(args)\n",
    "\n",
    "model_org =  Combined_SO_dispatch_cvxpy(SO_layer_cvxpy,intra_dispatch_cvxpy, copy.deepcopy(model_load)).to(device)\n",
    "model_org.to(device)\n",
    "\n",
    "cost_list_optnet= []\n",
    "for i in range(29):\n",
    "    test_pred_mu_tensor=torch.tensor(test_pred_mu[i],dtype=torch.float64).unsqueeze(0).to(device)\n",
    "    test_pred_var_tensor=torch.tensor(test_pred_var[i],dtype=torch.float64).unsqueeze(0).to(device)\n",
    "    test_actual_tensor=torch.tensor(test_actual[i],dtype=torch.float64).unsqueeze(0).to(device)\n",
    "\n",
    "    alpha_sample_torch=torch.tensor(alpha_sample,dtype=torch.float64).unsqueeze(0).to(device)\n",
    "    alpha_z_sample_torch=torch.tensor(alpha_z_sample,dtype=torch.float64).unsqueeze(0).to(device)\n",
    "    rho_z_sample_torch=torch.tensor(rho_z_sample,dtype=torch.float64).unsqueeze(0).to(device)\n",
    "    rho_r_sample_torch=torch.tensor(rho_r_sample,dtype=torch.float64).unsqueeze(0).to(device)\n",
    "    set_seed(42)\n",
    "    solution_DA, solution_RT, cost = model_org.forward(\n",
    "                        args, test_pred_mu_tensor,test_pred_var_tensor, test_actual_tensor,\n",
    "                        alpha_sample_torch, alpha_z_sample_torch, rho_z_sample_torch, rho_r_sample_torch\n",
    "                    )\n",
    "    cost_list_optnet.append(cost.detach().cpu().numpy())\n",
    "print('Average cost over 30 runs (OptNet):', np.mean(cost_list_optnet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eebb30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from E2E import E2E_test_ideal,E2E_test,E2E_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e535b0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Objective: 2392.189740770122\n",
      "Test Objective: 2650.9600326568443\n",
      "Test Objective: 2622.024603134539\n",
      "Test Objective: 2452.369167679563\n",
      "Test Objective: 2364.880033939213\n",
      "No more data to read.\n",
      "Test Objective: 2284.506774159131\n",
      "Test Objective: 2247.082523717896\n",
      "Test Objective: 2236.2070249696026\n",
      "Test Objective: 2262.8930252153823\n",
      "Test Objective: 2224.849023435543\n",
      "Test Objective: 2242.131774289995\n",
      "Test Objective: 2308.9750264611066\n",
      "Test Objective: 2229.8297750371958\n",
      "Test Objective: 2270.1205253678563\n",
      "Test Objective: 2295.593524911773\n",
      "Test Objective: 2264.491526149967\n",
      "Test Objective: 2249.119024886811\n",
      "Test Objective: 2351.0057758291214\n",
      "Test Objective: 2171.1572728749243\n",
      "Test Objective: 2306.5100258642424\n",
      "Test Objective: 2289.2892756928554\n",
      "Test Objective: 2335.115774776379\n",
      "Test Objective: 2240.5287737908757\n",
      "Test Objective: 2247.936270467775\n",
      "Test Objective: 2287.7602780300904\n",
      "Test Objective: 2251.805274657032\n",
      "Test Objective: 2187.4802729311095\n",
      "Test Objective: 2324.818026683723\n",
      "No more data to read.\n",
      "Test Objective: 2278.9395246915983\n",
      "Test Objective: 2361.7630275164943\n",
      "Test Objective: 2390.0020284077427\n",
      "Test Objective: 2327.2705267184215\n",
      "Test Objective: 2196.9617752167937\n",
      "Test Objective: 2373.0562774521786\n",
      "Test Objective: 2294.426525185706\n",
      "Test Objective: 2315.209028206334\n",
      "Test Objective: 2297.5050259723785\n",
      "Test Objective: 2295.1205218295654\n",
      "Test Objective: 2322.5035275118075\n",
      "Test Objective: 2251.473275782818\n",
      "Test Objective: 2321.4640275035126\n",
      "Test Objective: 2235.847024159496\n",
      "Test Objective: 2300.454276387686\n",
      "Test Objective: 2392.175279196492\n",
      "Test Objective: 2247.765024343328\n",
      "Test Objective: 2250.2237719588784\n",
      "Test Objective: 2290.3827736504772\n",
      "Test Objective: 2335.966275382847\n",
      "Test Objective: 2251.0301572275844\n",
      "No more data to read.\n"
     ]
    }
   ],
   "source": [
    "from E2E import E2E_test_ideal,E2E_test,E2E_train\n",
    "_,_,cost_list_ideal,_,_,_=E2E_test_ideal(args, model_org, combined_test_loader, train_load_data.scaler_y)\n",
    "_,_,cost_list_train_ideal,_,_,_=E2E_test_ideal(args, model_org, combined_train_loader, train_load_data.scaler_y)\n",
    "_,_,cost_list_val_ideal,_,_,_=E2E_test_ideal(args, model_org, combined_val_loader, train_load_data.scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56aa4318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Objective: 2730.35968582262\n",
      "Test Objective: 3305.7642859033117\n",
      "Test Objective: 3068.0842011297345\n",
      "Test Objective: 2950.1338194991868\n",
      "Test Objective: 2679.8912313155965\n",
      "No more data to read.\n",
      "Test Objective: 2703.5863327665643\n",
      "Test Objective: 2965.926567911718\n",
      "Test Objective: 3048.9472337338307\n",
      "Test Objective: 2806.7592325378864\n",
      "Test Objective: 2507.9257192378036\n",
      "Test Objective: 2851.048582467948\n",
      "Test Objective: 2795.15679230802\n",
      "Test Objective: 2830.9599999995753\n",
      "Test Objective: 2715.8539905395646\n",
      "Test Objective: 2651.811947611509\n",
      "Test Objective: 2832.5235042294244\n",
      "Test Objective: 2634.4148088930333\n",
      "Test Objective: 2673.897786105424\n",
      "Test Objective: 2908.340094538465\n",
      "Test Objective: 2808.547674290036\n",
      "Test Objective: 3076.4671153825407\n",
      "Test Objective: 2624.9618634900326\n",
      "Test Objective: 2730.389420289868\n",
      "Test Objective: 2616.5212865831313\n",
      "Test Objective: 2904.683253898713\n",
      "Test Objective: 2535.8268927700515\n",
      "No more data to read.\n",
      "Test Objective: 2748.828798809909\n",
      "Test Objective: 2596.182449284088\n",
      "Test Objective: 2681.749754459248\n",
      "Test Objective: 2695.51191074932\n",
      "Test Objective: 2597.9543107171653\n",
      "Test Objective: 2573.550530961823\n",
      "Test Objective: 2638.504457642656\n",
      "Test Objective: 2618.774638117612\n",
      "Test Objective: 2685.5341946343515\n",
      "Test Objective: 2920.8834644914978\n",
      "Test Objective: 2643.8766601590005\n",
      "Test Objective: 2674.0224562592084\n",
      "Test Objective: 2781.919084073098\n",
      "Test Objective: 2573.9238452687396\n",
      "Test Objective: 2874.041826975438\n",
      "Test Objective: 2787.9684571359917\n",
      "Test Objective: 2747.6735497310815\n",
      "Test Objective: 2534.3119035595037\n",
      "Test Objective: 2767.961353089668\n",
      "Test Objective: 2723.3041659222017\n",
      "Test Objective: 2579.656670389648\n",
      "Test Objective: 2506.6530072955206\n",
      "Test Objective: 2711.2897082268555\n",
      "No more data to read.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "_,_, cost_list_test,forecasts_mu_test,forecasts_var_test,actual_load_test=E2E_test(args, model_org, combined_test_loader, train_load_data.scaler_y)\n",
    "_,_, cost_list_val,forecasts_mu_val,forecasts_var_val,actual_load_val=E2E_test(args, model_org, combined_val_loader, train_load_data.scaler_y)\n",
    "_,_, cost_list_train,forecasts_mu_train,forecasts_var_train,actual_load_train=E2E_test(args, model_org, combined_train_loader, train_load_data.scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5de5cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "e2e epoch: 0\n",
      "===============================\n",
      "===============================\n",
      "e2e epoch: 1\n",
      "===============================\n",
      "===============================\n",
      "e2e epoch: 2\n",
      "===============================\n",
      "Test Objective: 2704.250973881428\n",
      "Test Objective: 3177.762683433777\n",
      "Test Objective: 3061.705610649421\n",
      "Test Objective: 2938.5025480871604\n",
      "Test Objective: 2670.9718966554324\n",
      "No more data to read.\n",
      "Test Objective: 2654.4248121454657\n",
      "Test Objective: 2924.225576183768\n",
      "Test Objective: 3017.2229407662217\n",
      "Test Objective: 2781.599785917564\n",
      "Test Objective: 2517.7338321324214\n",
      "Test Objective: 2806.020845850208\n",
      "Test Objective: 2755.061967364659\n",
      "Test Objective: 2789.2137908789446\n",
      "Test Objective: 2676.5499862374772\n",
      "Test Objective: 2615.6018988374717\n",
      "Test Objective: 2812.7129893938054\n",
      "Test Objective: 2607.2781737221503\n",
      "Test Objective: 2660.6346650445057\n",
      "Test Objective: 2875.194776444027\n",
      "Test Objective: 2757.848757176364\n",
      "Test Objective: 3028.467261039173\n",
      "Test Objective: 2628.020639760345\n",
      "Test Objective: 2675.212938115553\n",
      "Test Objective: 2593.0172603118826\n",
      "Test Objective: 2842.762088488345\n",
      "Test Objective: 2528.688633452867\n",
      "No more data to read.\n",
      "Test Objective: 2704.697221260057\n",
      "Test Objective: 2569.9977540642467\n",
      "Test Objective: 2632.7715364756887\n",
      "Test Objective: 2656.4046319253102\n",
      "Test Objective: 2582.0017830653733\n",
      "Test Objective: 2540.8947373693068\n",
      "Test Objective: 2615.4995246692024\n",
      "Test Objective: 2603.2914272266944\n",
      "Test Objective: 2647.092654469817\n",
      "Test Objective: 2877.0367349130593\n",
      "Test Objective: 2603.508114921832\n",
      "Test Objective: 2652.9931434550444\n",
      "Test Objective: 2742.8882885874264\n",
      "Test Objective: 2521.0512957809333\n",
      "Test Objective: 2821.314694860203\n",
      "Test Objective: 2741.8221368250297\n",
      "Test Objective: 2725.13334915464\n",
      "Test Objective: 2514.923798911086\n",
      "Test Objective: 2726.3772464888007\n",
      "Test Objective: 2688.631562340913\n",
      "Test Objective: 2564.057219104867\n",
      "Test Objective: 2486.6338220534835\n",
      "Test Objective: 2717.4019244430383\n",
      "No more data to read.\n"
     ]
    }
   ],
   "source": [
    "model_e2e_deterministic=E2E_train(args, model_org, combined_train_loader, combined_test_loader,train_load_data.scaler_y)\n",
    "_,_, cost_list_test_optnet,forecasts_mu_test_optnet,forecasts_var_test_optnet,actual_load_test_optnet=E2E_test(args, model_e2e_deterministic, combined_test_loader, train_load_data.scaler_y, time_flag=True)\n",
    "_,_,cost_list_val_optnet,forecasts_mu_val_optnet,forecasts_var_val_optnet,actual_load_val_optnet=E2E_test(args, model_e2e_deterministic, combined_val_loader, train_load_data.scaler_y, time_flag=True)\n",
    "_,_,cost_list_train_optnet,forecasts_mu_train_optnet,forecasts_var_train_optnet,actual_load_train_optnet=E2E_test(args, model_e2e_deterministic, combined_train_loader, train_load_data.scaler_y, time_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a6e3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from E2E import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "227141cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(train_load_data.scaler_y, StandardScaler):\n",
    "    scale=train_load_data.scaler_y.scale_\n",
    "    mean=train_load_data.scaler_y.mean_\n",
    "elif isinstance(train_load_data.scaler_y, MinMaxScaler):\n",
    "    scale=train_load_data.scaler_y.data_max_-train_load_data.scaler_y.data_min_\n",
    "    mean=train_load_data.scaler_y.data_min_\n",
    "\n",
    "cost_list_test_insert=[cost_list_test[i]-cost_list_ideal[i] for i in range(len(cost_list_test))]\n",
    "actual_load_test_insert=[tensor.detach().cpu().numpy() for tensor in actual_load_test]\n",
    "pred_mu_test_insert=[tensor.detach().cpu().numpy() for tensor in forecasts_mu_test]\n",
    "pred_var_test_insert=[tensor.detach().cpu().numpy() for tensor in forecasts_var_test]\n",
    "\n",
    "cost_list_val_insert=[cost_list_val[i]-cost_list_val_ideal[i] for i in range(len(cost_list_val))]\n",
    "actual_load_val_insert=[tensor.detach().cpu().numpy() for tensor in actual_load_val]\n",
    "pred_mu_val_insert=[tensor.detach().cpu().numpy() for tensor in forecasts_mu_val]\n",
    "pred_var_val_insert=[tensor.detach().cpu().numpy() for tensor in forecasts_var_val]\n",
    "\n",
    "cost_list_train_insert=[cost_list_train[i]-cost_list_train_ideal[i] for i in range(len(cost_list_train))]\n",
    "actual_load_train_insert=[tensor.detach().cpu().numpy() for tensor in actual_load_train]\n",
    "pred_mu_train_insert=[tensor.detach().cpu().numpy() for tensor in forecasts_mu_train]\n",
    "pred_var_train_insert=[tensor.detach().cpu().numpy() for tensor in forecasts_var_train]\n",
    "\n",
    "cost_list_test_optnet_insert=[cost_list_test_optnet[i]-cost_list_ideal[i] for i in range(len(cost_list_test_optnet))]\n",
    "actual_load_test_optnet_insert=[tensor.detach().cpu().numpy() for tensor in actual_load_test_optnet]\n",
    "pred_mu_test_optnet_insert=[tensor.detach().cpu().numpy() for tensor in forecasts_mu_test_optnet]\n",
    "pred_var_test_optnet_insert=[tensor.detach().cpu().numpy() for tensor in forecasts_var_test_optnet]\n",
    "\n",
    "cost_list_val_optnet_insert=[cost_list_val_optnet[i]-cost_list_val_ideal[i] for i in range(len(cost_list_val_optnet))]\n",
    "actual_load_val_optnet_insert=[tensor.detach().cpu().numpy() for tensor in actual_load_val_optnet]\n",
    "pred_mu_val_optnet_insert=[tensor.detach().cpu().numpy() for tensor in forecasts_mu_val_optnet]\n",
    "pred_var_val_optnet_insert=[tensor.detach().cpu().numpy() for tensor in forecasts_var_val_optnet]\n",
    "\n",
    "cost_list_train_optnet_insert=[cost_list_train_optnet[i]-cost_list_train_ideal[i] for i in range(len(cost_list_train_optnet))]\n",
    "actual_load_train_optnet_insert=[tensor.detach().cpu().numpy() for tensor in actual_load_train_optnet]\n",
    "pred_mu_train_optnet_insert=[tensor.detach().cpu().numpy() for tensor in forecasts_mu_train_optnet]\n",
    "pred_var_train_optnet_insert=[tensor.detach().cpu().numpy() for tensor in forecasts_var_train_optnet]\n",
    "\n",
    "history_X_insert_train=[np.concatenate([history_X_train[i], pred_mu_train_optnet_insert[i]]) for i in range(len(pred_mu_train_optnet_insert))]\n",
    "history_X_insert_val=[np.concatenate([history_X_val[i], pred_mu_val_optnet_insert[i]]) for i in range(len(pred_mu_val_optnet_insert))]\n",
    "history_X_insert_test=[np.concatenate([history_X_test[i], pred_mu_test_optnet_insert[i]]) for i in range(len(pred_mu_test_optnet_insert))]\n",
    "\n",
    "\n",
    "db_train = CurveDictDB()\n",
    "cur_id_start = max(db_train.data.keys(), default=0) + 1\n",
    "for i, (cost, pred_mu,pred_var, fine_tuned_mu,fine_tuned_var, actual_load, history_X) in enumerate(zip(\n",
    "                    cost_list_train_insert, \n",
    "                     pred_mu_train_insert,pred_var_train_insert, \n",
    "                     pred_mu_test_optnet_insert,pred_var_test_optnet_insert, \n",
    "                     actual_load_train_insert,history_X_insert_train)):\n",
    "    record = {\n",
    "        'id': cur_id_start + i,\n",
    "        'flag': 0,\n",
    "        'prompt': '',\n",
    "        'load': pred_mu,\n",
    "        'pred_var': pred_var,\n",
    "        'fine_tuned_load': fine_tuned_mu,\n",
    "        'fine_tuned_var': fine_tuned_var,\n",
    "        'cost': cost,\n",
    "        'actual_load': actual_load,\n",
    "        'cost_reduction': 0, # 1代表成本比fine tune前低\n",
    "        'history_X': history_X\n",
    "    }\n",
    "    db_train.insert(record)\n",
    "\n",
    "db_val = CurveDictDB()\n",
    "cur_id_start_val = max(db_val.data.keys(), default=0) + 1\n",
    "for i, (cost, pred_mu, pred_var, fine_tuned_mu,fine_tuned_var, actual_load, history_X) in enumerate(zip(\n",
    "    cost_list_val_insert, \n",
    "    pred_mu_val_insert, pred_var_val_insert,\n",
    "    pred_mu_train_optnet_insert, pred_var_train_optnet_insert, \n",
    "    actual_load_val_optnet_insert, history_X_insert_val)):\n",
    "    record = {\n",
    "        'id': cur_id_start_val + i,\n",
    "        'flag': 0,\n",
    "        'prompt': '',\n",
    "        'load': pred_mu,\n",
    "        'pred_var': pred_var,\n",
    "        'fine_tuned_load': fine_tuned_mu,\n",
    "        'fine_tuned_var': fine_tuned_var,\n",
    "        'cost': cost,\n",
    "        'actual_load': actual_load,\n",
    "        'cost_reduction': 0,\n",
    "        'history_X': history_X\n",
    "    }\n",
    "    db_val.insert(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "522150ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_sys(args,data):\n",
    "    # Return English prompt\n",
    "    prompt = (\n",
    "        f\"You are a power dispatch expert. There are {args.N_g} generating units:\\n\"\n",
    "        f\"Unit 1: {args.x_min}~{args.x_max} MW, \"\n",
    "        f\"Unit 2: {args.x_min}~{args.x_max} MW, \"\n",
    "        f\"Unit 3: {args.x_min}~{args.x_max} MW.\\n\"\n",
    "        f\"Unit 1 generation cost: {args.alpha[0:args.T]}*x RMB/kWh, \"\n",
    "        f\"Unit 2 generation cost: {args.alpha[args.T:2*args.T]}*x RMB/kWh, \"\n",
    "        f\"Unit 3 generation cost: {args.alpha[args.T*2:args.T*3]}*x RMB/kWh.\\n\"\n",
    "        f\"Unit 1 positive reserve limit: {args.rho_z_pos[0:args.T]} RMB/kWh, \"\n",
    "        f\"Unit 1 negative reserve limit: {args.rho_z_neg[0:args.T]} RMB/kWh.\\n\"\n",
    "        f\"Unit 2 positive reserve limit: {args.rho_z_pos[args.T:2*args.T]} RMB/kWh, \"\n",
    "        f\"Unit 2 negative reserve limit: {args.rho_z_neg[args.T:2*args.T]} RMB/kWh.\\n\"\n",
    "        f\"Unit 3 positive reserve limit: {args.rho_z_pos[args.T*2:args.T*3]} RMB/kWh, \"\n",
    "        f\"Unit 3 negative reserve limit: {args.rho_z_neg[args.T*2:args.T*3]} RMB/kWh.\\n\"   \n",
    "        f\"Fine tune the predicted load curve to minimize the cost of generation, you can be brave to make bold adjustments within safety limits.\\n\"\n",
    "        #f\"Predicted load: {data['load']}\\n\"\n",
    "        #f\"Predicted standard deviation: {data['pred_var']}\\n\"\n",
    "    )\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d90caf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_require_prompt = \"\"\"Please learn from the few-shot record and derived a combined strategy to adjust the original load curve.\n",
    "    You can only change several time points, and each point can only be changed within ±10% of the original value.\n",
    "    Output a Python function named \"adjustment_strategy\" that implements the optimization strategy. The function should take the original load curve as input and return a list of 24 delta values (changes to apply).\n",
    "\n",
    "    Requirements:\n",
    "    1. Define a function: def adjustment_strategy(original_load: list, original_var: list)-> deltas_mean:list,deltas_std:list.\n",
    "    2. The function must return a list of 24 numbers (deltas)\n",
    "    3. Use only basic Python operations (no external libraries)\n",
    "    4. Include comments explaining your strategy\n",
    "    5. Example:\n",
    "        def adjustment_strategy(original_load,original_var):\n",
    "            deltas_mean = [0] * 24\n",
    "            deltas_std = [0] * 24\n",
    "            if 20 <= i <22:\n",
    "                deltas_mean[i] = -original_load[i] * 0.02  # Reduce by 2%\n",
    "                deltas_std[i] = -original_var[i] * 0.01  # Reduce by 2%\n",
    "            return deltas_mean, deltas_std\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e65126a",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f3c492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_prompt_generate(args, similar_days, max_strategies=10, max_attempts=5,failure_strategy=None):\n",
    "    \"\"\"\n",
    "    Generate few-shot prompts for small-scale adjustment strategies.\n",
    "    Adjusts no more than 5 time points at a time, gradually building a strategy library.\n",
    "\n",
    "    Args:\n",
    "        args: Model arguments/parameters\n",
    "        similar_days: List of data for similar days\n",
    "        max_strategies: Maximum number of effective strategies\n",
    "        max_attempts: Maximum number of attempts\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Strategy history string, List of valid strategies)\n",
    "    \"\"\"\n",
    "    # Get average load of similar days\n",
    "    similar_day_mu = np.mean([day['load'] for day in similar_days], axis=0)\n",
    "    similar_day_var = np.mean([day['pred_var'] for day in similar_days], axis=0)\n",
    "\n",
    "    similar_day_actual = np.mean([day['actual_load'] for day in similar_days], axis=0)\n",
    "    \n",
    "    # similar_day_actual_load_numpy = train_load_data.scaler_y.inverse_transform(np.array(similar_day_actual_nor).reshape(1,-1))[0]\n",
    "\n",
    "    _,_, original_cost = optimization_module.forward(similar_day_mu, similar_day_var, similar_day_actual)\n",
    "\n",
    "    original_cost = original_cost.item()\n",
    "    \n",
    "    # Strategy generation prompt template\n",
    "    sim_data = {\"load\": similar_day_mu, \"pred_var\": similar_day_var}\n",
    "    system_prompt = generate_prompt_sys(args, sim_data)\n",
    "    higher_flag = \"higher\" if sum(np.array(similar_day_mu) - np.array(similar_day_actual)) > 0 else \"lower\"\n",
    "    reduce_flag = \"reduce\" if higher_flag == \"higher\" else \"increase\"\n",
    "    system_prompt += f\"\"\"\\n The maximum load occurs at {int(np.argmax(similar_day_mu))} hour, and the minimum load occurs at {int(np.argmin(similar_day_mu))} hour.\\n\\n\"\"\"\n",
    "    system_prompt += f\"\"\"\n",
    "    You have two approach to reduce cost:\n",
    "\n",
    "    1. Compare the actual value and forecast of the similar day, try to learn some errors reduce strategy. In this case, the similar day forecast is {higher_flag} than actual, so you can try to {reduce_flag} the load in some hours to reduce cost.\n",
    "    2. Compare the future positive and negative reserve prices.\n",
    "    - If the positive reserve price is much higher than the negative reserve price, you should schedule more generation in the day-ahead market.\n",
    "    - If the negative reserve price is higher, schedule less generation to reduce potential costs.\n",
    "    \"\"\"\n",
    "\n",
    "    if failure_strategy==None:\n",
    "        pass\n",
    "    else:\n",
    "        system_prompt='Here is failed strategy:\\n'+failure_strategy\n",
    "\n",
    "    output_require_prompt = f\"\"\"\n",
    "    You are an expert in electricity load curve optimization. Your task is to generate Python functions that implement small-scale optimization strategies for daily electricity load curves.\n",
    "\n",
    "    Requirements:\n",
    "    1. Generate exactly 8 distinct Python functions named \"strategy_1\", \"strategy_2\", \"strategy_3\", \"strategy_4\", \"strategy_5\", \"strategy_6\", \"strategy_7\", and \"strategy_8\".\n",
    "    2. The strategy should focus on a *different* part of the load curve, avoiding concentrating all changes in same time intervals.\n",
    "    2. Each function must:\n",
    "       - Take two arguments: the original load curve (list of 24 hourly values) and the original variance curve (list of 24 hourly values)\n",
    "       - Return two lists of 24 numbers (deltas) representing adjustments to mean and variance to each hour\n",
    "    3. Each strategy must:\n",
    "       - Adjust no more than 5 time points (hours)\n",
    "       - Target adjacent hours (e.g., 7pm to 9pm)\n",
    "       - Keep adjustments within ±10% of the original value at each hour\n",
    "       - Try to be different from other strategies.\n",
    "    4. Use only basic Python operations (no external libraries)\n",
    "    5. Include comments explaining:\n",
    "       - Which specific hours are targeted\n",
    "       - Why this strategy might reduce electricity costs\n",
    "    6. Example strategies:\n",
    "\n",
    "    Example 1: Reduce evening peak\n",
    "    def strategy_1(original_load, original_var):\n",
    "        # Focus: Reduce peak at 18:00 and 19:00 only\n",
    "        deltas_mean = [0] * 24\n",
    "        deltas_std = [0] * 24\n",
    "        # Only adjust hours 18 and 19\n",
    "        deltas_mean[18] = -original_load[18] * 0.05  # Reduce by 2%\n",
    "        deltas_mean[19] = -original_load[19] * 0.05  # Reduce by 2%\n",
    "        deltas_std[18] = -original_var[18] * 0.03  # Reduce by 2%\n",
    "        deltas_std[19] = -original_var[19] * 0.03  # Reduce by 2%\n",
    "\n",
    "        return deltas_mean, deltas_std\n",
    "\n",
    "    Example 2: Shift load from afternoon to late afternoon\n",
    "    def strategy_2(original_load, original_var):\n",
    "        # Focus: Shift load from afternoon to late afternoon\n",
    "        deltas_mean = [0] * 24\n",
    "        deltas_std = [0] * 24\n",
    "        # Only adjust hours 14 and 15\n",
    "        deltas_mean[14] = -original_load[14] * 0.04  # Reduce at 14:00\n",
    "        deltas_mean[15] = original_load[14] * 0.04   # Increase at 15:00\n",
    "        deltas_std[14] = -original_var[14] * 0.02  # Reduce at 14:00\n",
    "        deltas_std[15] = original_var[14] * 0.02   # Increase at 15:00\n",
    "        return deltas_mean, deltas_std\n",
    "\n",
    "    Example 3: Increase off-peak consumption\n",
    "    def strategy_3(original_load, original_var):\n",
    "        # Focus: Slightly increase off-peak at 2:00 and 3:00\n",
    "        deltas_mean = [0] * 24\n",
    "        deltas_std = [0] * 24\n",
    "        # Only adjust hours 2 and 3\n",
    "        deltas_mean[2] = original_load[2] * 0.03  # Increase by 1%\n",
    "        deltas_mean[3] = original_load[3] * 0.03  # Increase by 1%\n",
    "        deltas_std[2] = original_var[2] * 0.03  # Increase by 1%\n",
    "        deltas_std[3] = original_var[3] * 0.03  # Increase by 1%\n",
    "        return deltas_mean, deltas_std\n",
    "\n",
    "    Example 4: Flatten morning peak\n",
    "    def strategy_4(original_load, original_var):\n",
    "        # Focus: Reduce morning peak at 8:00 and shift to 9:00\n",
    "        deltas_mean = [0] * 24\n",
    "        deltas_std = [0] * 24\n",
    "        # Only adjust hours 8 and 9\n",
    "        deltas_mean[8] = -original_load[8] * 0.05  # Reduce at 8:00\n",
    "        deltas_mean[9] = original_load[8] * 0.05   # Increase at 9:00\n",
    "        deltas_std[8] = -original_var[8] * 0.02  # Reduce at 8:00\n",
    "        deltas_std[9] = original_var[8] * 0.02   # Increase at 9:00\n",
    "        return deltas_mean, deltas_std\n",
    "\n",
    "    Example 5: Smooth transition between peak and off-peak\n",
    "    def strategy_5(original_load,original_var):\n",
    "        # Focus: Smooth transition from evening to night (20:00-21:00)\n",
    "        deltas_mean = [0] * 24\n",
    "        deltas_std = [0] * 24\n",
    "        # Only adjust hours 20 and 21\n",
    "        deltas_mean[20] = -original_load[20] * 0.06  # Reduce at 20:00\n",
    "        deltas_mean[21] = -original_load[20] * 0.06   # Increase at 21:00\n",
    "        deltas_std[20] = -original_var[20] * 0.03 # Reduce at 20:00\n",
    "        deltas_std[21] = -original_var[20] * 0.03   # Increase at 21:00\n",
    "        return deltas_mean, deltas_std\n",
    "    \"\"\"\n",
    "    \n",
    "    # Store valid strategies\n",
    "    valid_strategies = []\n",
    "    strategy_history = \"\"\n",
    "    attempt_count = 0\n",
    "    full_prompt = ''\n",
    "    while (len(valid_strategies) < max_strategies and attempt_count < max_attempts) or (len(valid_strategies) < int(max_strategies)/2 and attempt_count < 10):\n",
    "        attempt_count += 1\n",
    "        print(f\"Strategy generation attempt #{attempt_count} (Current valid strategies: {len(valid_strategies)}/{max_strategies})\")\n",
    "        if valid_strategies != []:\n",
    "            history_snippet = 'Here are some previously discovered effective small-scale adjustment strategies:\\n, you are modified based on these strategies or regenerate new strategies.\\n'\n",
    "            for i in range(len(valid_strategies)):\n",
    "                history_snippet += (f\"Strategy {i+1}:\\n{valid_strategies[i]['code']}\\n\\n\")\n",
    "        else:\n",
    "            history_snippet = \"No previously discovered effective small-scale adjustment strategies.\"\n",
    "        if attempt_count >= int(max_attempts)/2:\n",
    "            print('Give actual value')\n",
    "            full_prompt += (f\"SYSTEM INSTRUCTIONS:\\n{system_prompt}\\n\\n\"\n",
    "                            f\"HISTORICAL CONTEXT:\\n{history_snippet}\\n\\n\"\n",
    "                            f\"This is your FINAL attempt for this similar day. The actual load is {similar_day_actual}. Use all your knowledge and experience to produce the best possible optimized load curves.\\n\\n\"\n",
    "                            f\"TASK REQUIREMENTS:\\n{output_require_prompt}\\n\\n\")\n",
    "        else:\n",
    "            full_prompt += (\n",
    "                            f\"SYSTEM INSTRUCTIONS:\\n{system_prompt}\\n\\n\"\n",
    "                            f\"HISTORICAL CONTEXT:\\n{history_snippet}\\n\\n\"\n",
    "                            f\"TASK REQUIREMENTS:\\n{output_require_prompt}\\n\\n\")\n",
    "        try:\n",
    "            if args.LLM_type == 'Qwen':\n",
    "                response = Generation.call(\n",
    "                model=\"qwen-plus\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": full_prompt},\n",
    "                ],\n",
    "                parameters={\n",
    "                    \"temperature\": 0.5,\n",
    "                    \"max_tokens\": 3072,\n",
    "                    \"top_k\": 20\n",
    "                }\n",
    "                )\n",
    "                raw_text = response.output.text.strip()\n",
    "                func_code = extract_pure_code(raw_text)\n",
    "\n",
    "            elif args.LLM_type == 'Deepseek':\n",
    "                client = OpenAI(api_key=DEEPSEEK_API_KEY,\n",
    "                base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"deepseek-chat\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": full_prompt},\n",
    "                    ],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=3072,\n",
    "                    stream=False,\n",
    "                )\n",
    "\n",
    "                raw_text = response.choices[0].message.content.strip()\n",
    "                func_code = extract_pure_code(raw_text)\n",
    "\n",
    "            elif args.LLM_type == 'Llama':\n",
    "                client = Together(api_key=LLAMA_API_KEY)\n",
    "                response = client.chat.completions.create(\n",
    "                    model=\"meta-llama/Llama-4-Scout-17B-16E-Instruct\",  # Can be replaced with other Llama versions\n",
    "                    messages=[\n",
    "                    {\"role\": \"system\", \"content\": full_prompt},\n",
    "                ],\n",
    "                temperature=1.2,\n",
    "                max_tokens=3072,\n",
    "                stream=False,\n",
    "                )\n",
    "                raw_text = response.choices[0].message.content.strip()\n",
    "                func_code = extract_pure_code(raw_text)\n",
    "\n",
    "            # Execute all strategy functions (evaluate separately)\n",
    "            similar_day_mu_nor = train_load_data.scaler_y.transform(np.array(similar_day_mu).reshape(-1,1)).flatten()\n",
    "            if isinstance(train_load_data.scaler_y, StandardScaler):\n",
    "                similar_day_var_nor = np.array(similar_day_var).flatten()/train_load_data.scaler_y.scale_\n",
    "            elif isinstance(train_load_data.scaler_y, MinMaxScaler):\n",
    "                similar_day_var_nor = np.array(similar_day_var).flatten()/(train_load_data.scaler_y.data_max_-train_load_data.scaler_y.data_min_)\n",
    "            strategy_results = evaluate_individual_strategies(\n",
    "                func_code, \n",
    "                similar_day_mu_nor.tolist(),\n",
    "                similar_day_var_nor.tolist(),\n",
    "                max_change_percent=0.1\n",
    "            )\n",
    "            \n",
    "            if not strategy_results:\n",
    "                print(\"No valid strategy functions generated\")\n",
    "                continue\n",
    "                \n",
    "            for name, strategy in strategy_results.items():\n",
    "                try:\n",
    "                    # Apply strategy to similar day data\n",
    "                    adjusted_curve = strategy['adjusted_curve']\n",
    "                    adjusted_curve =  train_load_data.scaler_y.inverse_transform(np.array(adjusted_curve).reshape(-1,1)).flatten()\n",
    "                    _, _, strategy_cost = optimization_module.forward(adjusted_curve, similar_day_var, similar_day_actual)\n",
    "                    strategy_cost = strategy_cost.item()\n",
    "                    if strategy_cost < original_cost - 1:\n",
    "                        # Check the number of adjustment points\n",
    "                        adjusted_hours = sum(1 for delta in strategy['delta_curve_mean'] if abs(delta) > 1e-5)\n",
    "                        if adjusted_hours <= 5:#and strategy_cost not in [s['final_cost'] for s in valid_strategies]:  # Ensure only 5 or fewer time points are adjusted\n",
    "                            valid_strategies.append({\n",
    "                                'name': 'Strategy ' + str(len(valid_strategies)+1),\n",
    "                                'code': strategy['func_code'],\n",
    "                                'cost_reduction': original_cost - strategy_cost,\n",
    "                                'final_cost': strategy_cost,\n",
    "                                'original_cost': original_cost,\n",
    "                                'original_load' : similar_day_mu.tolist(),\n",
    "                                'original_var' : similar_day_var.tolist(),\n",
    "                                'actual_load': similar_day_actual.tolist(),\n",
    "                                'adjusted_curve': adjusted_curve,\n",
    "                                'delta_curve_var': strategy['delta_curve_var'],\n",
    "                                'adjusted_hours': adjusted_hours\n",
    "                            })\n",
    "                            \n",
    "                            # Add to history\n",
    "                            strategy_history += (\n",
    "                                f\"Strategy {name} reduced cost on similar day: {original_cost - strategy_cost:.2f}\\n\"\n",
    "                                f\"Adjusted hours: {adjusted_hours} hours\\n\"\n",
    "                                f\"Code:\\n{strategy['func_code']}\\n\\n\"\n",
    "                            )\n",
    "                            \n",
    "                            print(f\"Found valid strategy {name}, cost {strategy_cost:.2f}, original cost {original_cost:.2f}, (reduction {original_cost - strategy_cost:.2f})\")\n",
    "                            \n",
    "                            # If max strategies reached, break early\n",
    "                            if len(valid_strategies) >= max_strategies:\n",
    "                                break\n",
    "                except Exception as e:\n",
    "                    print(f\"Error evaluating strategy {name}: {str(e)}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Strategy generation exception: {str(e)}\")\n",
    "    \n",
    "    # If no valid strategies found, add an empty strategy note\n",
    "    if not valid_strategies:\n",
    "        strategy_history = \"No effective small-scale adjustment strategies found\"\n",
    "    \n",
    "    return strategy_history, valid_strategies\n",
    "\n",
    "def remove_comments(code_str):\n",
    "    # Remove multi-line comments (both triple double-quotes and triple single-quotes)\n",
    "    code_str = re.sub(r'(\"\"\"[\\s\\S]*?\"\"\"|\\'\\'\\'[\\s\\S]*?\\'\\'\\')', '', code_str)\n",
    "    # Remove single-line comments\n",
    "    code_str = re.sub(r'#.*', '', code_str)\n",
    "    # Remove excess empty lines\n",
    "    code_str = re.sub(r'\\n\\s*\\n', '\\n', code_str)\n",
    "    return code_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01de6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned_result_given_by_LLM = {\n",
    "    'selected_flag': [], 'actual_load': [], 'original_mu': [], 'optnet_mu': [],\n",
    "    'fine_tuned_mu': [], 'original_var': [], 'optnet_var': [],\n",
    "    'fine_tuned_var': [], 'cost_after': [], 'cost_org': [], 'cost_optnet': [],\n",
    "    'similar_mu': [], 'similar_var': [], 'similar_actual_load': [],\n",
    "    'few_shot_costs': [], 'few_shot_curves': [], 'few_shot_code': [], 'strategy_code': []\n",
    "}\n",
    "skip_samples = []\n",
    "validate_failures = []\n",
    "reflection_records = []\n",
    "\n",
    "for inqure_id in range(len(pred_mu_test_insert)):\n",
    "    print(f\"Processing inquiry {inqure_id+1}/{len(pred_mu_test_insert)}\")\n",
    "    data_for_inqure = {\n",
    "        'load': pred_mu_test_insert[inqure_id],\n",
    "        'fine_tuned_load': pred_mu_test_optnet_insert[inqure_id],\n",
    "        'pred_var': pred_var_test_insert[inqure_id],\n",
    "        'fine_tuned_var': pred_var_test_optnet_insert[inqure_id],\n",
    "    }\n",
    "\n",
    "    load_numpy_mu_org = np.array(data_for_inqure['load']) # train_load_data.scaler_y.inverse_transform(np.array(data_for_inqure['load']).reshape(1,-1))[0]\n",
    "    load_numpy_var_org = np.array(data_for_inqure['pred_var']) # .reshape(1,-1)*train_load_data.scaler_y.scale_\n",
    "    load_numpy_mu_optnet = np.array(data_for_inqure['fine_tuned_load']) # train_load_data.scaler_y.inverse_transform(np.array(data_for_inqure['fine_tuned_load']).reshape(1,-1))[0]\n",
    "    load_numpy_var_optnet = np.array(data_for_inqure['fine_tuned_var']) # .reshape(1,-1)*train_load_data.scaler_y.scale_\n",
    "    # actual_load_numpy= train_load_data.scaler_y.inverse_transform(np.array(data_for_inqure['fine_tuned_load']).reshape(1,-1))[0]\n",
    "    actual_load_numpy = np.array(actual_load_test_insert[inqure_id])\n",
    "\n",
    "    similar_days = db_train.get_top_k_unique_loads(data_for_inqure['load'], k=3, q=1)[0:3]\n",
    "    average_similar_mu_org = np.mean([day['load'] for day in similar_days], axis=0)\n",
    "    average_similar_var_org = np.mean([day['pred_var'] for day in similar_days], axis=0)\n",
    "    average_similar_load_actual = np.mean([day['actual_load'] for day in similar_days], axis=0)\n",
    "    average_similar_mu_optnet = np.mean([day['fine_tuned_load'] for day in similar_days], axis=0)\n",
    "    average_similar_var_optnet = np.mean([day['fine_tuned_var'] for day in similar_days], axis=0)\n",
    "    _, _, obj_org_similar_days = optimization_module.forward(average_similar_mu_org, average_similar_var_org, average_similar_load_actual)\n",
    "    obj_org_similar_days = obj_org_similar_days.item()\n",
    "    \n",
    "    _, _, obj_optnet_similar_days = optimization_module.forward(average_similar_mu_optnet, average_similar_var_optnet, average_similar_load_actual)\n",
    "    obj_optnet_similar_days = obj_optnet_similar_days.item()\n",
    "\n",
    "    selected_flag = 'optnet'\n",
    "    load_nor= data_for_inqure['fine_tuned_load'] \n",
    "    average_similar_mu = average_similar_mu_optnet\n",
    "    average_similar_var = average_similar_var_optnet\n",
    "    actual_load = average_similar_load_actual\n",
    "\n",
    "    higher_flag = \"higher\" if sum(np.array(average_similar_mu) - np.array(actual_load)) > 0 else \"lower\"\n",
    "    reduce_flag = \"reduce\" if higher_flag == \"higher\" else \"increase\"\n",
    "    print(f\"Found {len(similar_days)} similar days for inquiry {inqure_id}\")\n",
    "    system_prompt = generate_prompt_sys(args, data_for_inqure)\n",
    "\n",
    "    full_user_prompt = f\"SYSTEM INSTRUCTIONS:\\n{system_prompt}.\"\n",
    "    full_user_prompt += f\"\"\"\\n\\nHint: You have two approach to reduce cost:\n",
    "\n",
    "    1. Compare the actual value and forecast of the similar day, try to learn some errors reduce strategy. In history similar day, we find the forecasts {higher_flag} than actual, so you can try to {reduce_flag} the load in some hours to reduce cost.\n",
    "    2. Compare the future positive and negative reserve prices.\n",
    "    - If the positive reserve price is much higher than the negative reserve price, you should schedule more generation in the day-ahead market.\n",
    "    - If the negative reserve price is higher, schedule less generation to reduce potential costs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Few-shot code integration\n",
    "    print(\"Generating few-shot prompts based on similar days...\")\n",
    "    strategy_history, valid_strategies = few_shot_prompt_generate(args, similar_days, max_strategies=20, max_attempts=6)\n",
    "    \n",
    "    selected_strategy = []\n",
    "    similar_days_val = db_val.get_top_k_unique_loads(data_for_inqure['load'], k=3, q=1)[0:3]\n",
    "    average_similar_mu_val = np.mean([day['load'] for day in similar_days_val], axis=0)\n",
    "    average_similar_var_val = np.mean([day['pred_var'] for day in similar_days_val], axis=0)\n",
    "    average_similar_load_actual_val = np.mean([day['actual_load'] for day in similar_days_val], axis=0)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(range(len(average_similar_mu_val)), average_similar_mu_val, markersize=8, marker='o', label='Original Load')\n",
    "    plt.plot(range(len(average_similar_mu_val)), average_similar_load_actual_val, markersize=8, marker='o', label='Actual Load')\n",
    "    \n",
    "    load_val_numpy = average_similar_mu_val.tolist()\n",
    "            \n",
    "    load_val_nor = train_load_data.scaler_y.transform(np.array(load_val_numpy).reshape(-1,1)).flatten()\n",
    "    if isinstance(train_load_data.scaler_y, StandardScaler):\n",
    "        load_val_var_nor = np.array(average_similar_var_val).flatten()/train_load_data.scaler_y.scale_\n",
    "    elif isinstance(train_load_data.scaler_y, MinMaxScaler):\n",
    "        load_val_var_nor = np.array(average_similar_var_val).flatten()/(train_load_data.scaler_y.data_max_-train_load_data.scaler_y.data_min_)\n",
    "    print('load_val_nor:', load_val_nor)\n",
    "    print('load_val_var_nor:', load_val_var_nor)\n",
    "    for strategy in valid_strategies:\n",
    "        strategy_result = evaluate_individual_strategies(\n",
    "            strategy['code'],\n",
    "            load_val_nor,\n",
    "            load_val_var_nor,\n",
    "            max_change_percent=0.1\n",
    "        )\n",
    "        selected_curve_val = strategy_result[list(strategy_result.keys())[0]]['adjusted_curve']\n",
    "        selected_curve_var_val = strategy_result[list(strategy_result.keys())[0]]['adjusted_curve_var']\n",
    "        print('selected_curve_val:', selected_curve_val)\n",
    "        print('selected_curve_var_val:', selected_curve_var_val)\n",
    "        fine_tune_load_val_numpy = train_load_data.scaler_y.inverse_transform(np.array(selected_curve_val).reshape(-1,1)).flatten()\n",
    "        if isinstance(train_load_data.scaler_y, StandardScaler):\n",
    "            fine_tune_var_val_numpy = np.array(selected_curve_var_val).flatten()*train_load_data.scaler_y.scale_\n",
    "        elif isinstance(train_load_data.scaler_y, MinMaxScaler):\n",
    "            fine_tune_var_val_numpy = np.array(selected_curve_var_val).flatten()*(train_load_data.scaler_y.data_max_-train_load_data.scaler_y.data_min_)\n",
    "        _, _, obj_org_val = optimization_module.forward(average_similar_mu_val, average_similar_var_val, average_similar_load_actual_val)\n",
    "        _, _, obj_fine_tune_val = optimization_module.forward(fine_tune_load_val_numpy, fine_tune_var_val_numpy, average_similar_load_actual_val)\n",
    "\n",
    "        if obj_org_val > obj_fine_tune_val:\n",
    "            selected_strategy.append(strategy)\n",
    "            plt.plot(range(24), fine_tune_load_val_numpy, label=strategy['name'], linestyle='--', alpha=0.8)\n",
    "            print(f\"Strategy {strategy['name']} succeeded on validation set, cost {obj_fine_tune_val.item():.2f}, original cost {obj_org_val.item():.2f}, (reduction {obj_org_val.item()-obj_fine_tune_val.item():.2f})\")\n",
    "        else:\n",
    "            print(f\"Strategy {strategy['name']} failed on validation set, cost {obj_fine_tune_val.item():.2f}, original cost {obj_org_val.item():.2f}, (increase {obj_org_val.item()-obj_fine_tune_val.item():.2f})\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # If no valid fine-tuning strategy is found, skip directly\n",
    "    if len(selected_strategy) == 0:\n",
    "        print(f\"Inquiry {inqure_id}: No valid strategy found, using original curve as fine-tuned result.\")\n",
    "        # _, _, obj_org = optimization_module.forward(average_similar_mu_val,average_similar_var_val, average_similar_load_actual_val)\n",
    "        # _, _, obj_optnet = optimization_module.forward(average_similar_mu_val,average_similar_var_val, average_similar_load_actual_val)\n",
    "\n",
    "        _,_, obj_org = optimization_module.forward(load_numpy_mu_org, load_numpy_var_org, actual_load_numpy)\n",
    "        _,_, obj_optnet = optimization_module.forward(load_numpy_mu_optnet, load_numpy_var_optnet, actual_load_numpy)\n",
    "\n",
    "        if selected_flag == 'org':\n",
    "            fine_tuned_result_given_by_LLM['fine_tuned_mu'].append(data_for_inqure['load'])\n",
    "            fine_tuned_result_given_by_LLM['fine_tuned_var'].append(data_for_inqure['pred_var'])\n",
    "            fine_tuned_result_given_by_LLM['cost_after'].append(obj_org.item())\n",
    "        else:\n",
    "            fine_tuned_result_given_by_LLM['fine_tuned_mu'].append(data_for_inqure['fine_tuned_load'])\n",
    "            fine_tuned_result_given_by_LLM['fine_tuned_var'].append(data_for_inqure['fine_tuned_var'])\n",
    "            fine_tuned_result_given_by_LLM['cost_after'].append(obj_optnet.item())\n",
    "\n",
    "        fine_tuned_result_given_by_LLM['selected_flag'].append(selected_flag)\n",
    "        fine_tuned_result_given_by_LLM['actual_load'].append(actual_load_test_insert[inqure_id])\n",
    "        fine_tuned_result_given_by_LLM['original_mu'].append(data_for_inqure['load'])\n",
    "        fine_tuned_result_given_by_LLM['optnet_mu'].append(data_for_inqure['fine_tuned_load'])\n",
    "        fine_tuned_result_given_by_LLM['original_var'].append(data_for_inqure['pred_var'])\n",
    "        fine_tuned_result_given_by_LLM['optnet_var'].append(data_for_inqure['fine_tuned_var'])\n",
    "        fine_tuned_result_given_by_LLM['similar_mu'].append(average_similar_mu_org.tolist())\n",
    "        fine_tuned_result_given_by_LLM['similar_var'].append(average_similar_var_org.tolist())\n",
    "        fine_tuned_result_given_by_LLM['similar_actual_load'].append(average_similar_load_actual.tolist())\n",
    "        fine_tuned_result_given_by_LLM['cost_org'].append(obj_org.item())\n",
    "        fine_tuned_result_given_by_LLM['cost_optnet'].append(obj_optnet.item())\n",
    "        fine_tuned_result_given_by_LLM['few_shot_costs'].append([])\n",
    "        fine_tuned_result_given_by_LLM['few_shot_curves'].append([])\n",
    "        fine_tuned_result_given_by_LLM['few_shot_code'].append([])\n",
    "        fine_tuned_result_given_by_LLM['strategy_code'].append('')\n",
    "        skip_samples.append(inqure_id)\n",
    "        \n",
    "        # Visualization\n",
    "        if len(fine_tuned_result_given_by_LLM['cost_org']) > 1:\n",
    "            print(np.mean(fine_tuned_result_given_by_LLM['cost_org']))\n",
    "            print(np.mean(fine_tuned_result_given_by_LLM['cost_optnet']))\n",
    "            print(np.mean(fine_tuned_result_given_by_LLM['cost_after']))\n",
    "            plt.figure(figsize=(8, 3))\n",
    "            plt.plot(\n",
    "                range(len(fine_tuned_result_given_by_LLM['cost_org'])),\n",
    "                np.array(fine_tuned_result_given_by_LLM['cost_optnet']) - np.array(fine_tuned_result_given_by_LLM['cost_after']),\n",
    "                label='Compared to optnet'\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(len(fine_tuned_result_given_by_LLM['cost_org'])),\n",
    "                np.array(fine_tuned_result_given_by_LLM['cost_org']) - np.array(fine_tuned_result_given_by_LLM['cost_after']),\n",
    "                label='Compared to original'\n",
    "            )\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        continue\n",
    "\n",
    "    # Construct few-shot LLM prompt\n",
    "    few_shot_costs = [s['final_cost'] for s in selected_strategy]\n",
    "    few_shot_curves = [s['adjusted_curve'] for s in selected_strategy]\n",
    "    few_shot_codes = [s['code'] for s in selected_strategy]\n",
    "    history_snippet_prompt = 'Here are some previously discovered effective adjustment strategies:\\n'\n",
    "    for i, s in enumerate(selected_strategy):\n",
    "        history_snippet_prompt += f\"Good strategy {i+1} from few-shot:\\n{s['code']}\\n\\n\"\n",
    "    history_snippet_prompt += f\"You should ensemble these strategy as you can only output one adjustment_strategy function.\\n\"\n",
    "\n",
    "    last_fail_reflections = get_fail_reflections_by_curve_distance(reflection_records, data_for_inqure['load'], max_num=1)\n",
    "    print(f\"Found {len(last_fail_reflections)} relevant failed reflection cases for inquiry {inqure_id}\")\n",
    "    fail_reflections_prompt = \"\"\n",
    "    if last_fail_reflections:\n",
    "        fail_reflections_prompt = 'You have failed in these examples and lead to cost increase, avoid these patterns:\\n'\n",
    "        fail_reflections_prompt += \"\\n### Previous failed adjustment text examples (avoid these patterns):\\n\"\n",
    "        for idx, record in enumerate(last_fail_reflections):\n",
    "            fail_reflections_prompt += (\n",
    "                f\"Fail Case {idx + 1}:\\n\"\n",
    "                f\"- Last failed strategy:\\n{remove_comments(record['strategy_code'])}\\n\\n\"\n",
    "                f\"- Successful strategy:\\n{(record['reflection_strategy'])}\\n\\n\"\n",
    "            )\n",
    "\n",
    "    if args.LLM_type == 'Qwen':\n",
    "        response = Generation.call(\n",
    "            model=\"qwen-plus\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": full_user_prompt},\n",
    "                {\"role\": \"user\", \"content\": output_require_prompt},\n",
    "                {\"role\": \"assistant\", \"content\": history_snippet_prompt},\n",
    "                {\"role\": \"assistant\", \"content\": fail_reflections_prompt},\n",
    "            ],\n",
    "            parameters={\n",
    "                \"temperature\": 0.1,\n",
    "                \"result_format\": \"text\",\n",
    "                \"max_tokens\": 2048,\n",
    "                \"top_k\": 10\n",
    "            }\n",
    "        )\n",
    "\n",
    "        raw_text = response.output.text.strip()\n",
    "        func_code = extract_pure_code(raw_text)\n",
    "\n",
    "    elif args.LLM_type == 'Deepseek':\n",
    "        client = OpenAI(api_key=DEEPSEEK_API_KEY,\n",
    "                base_url=\"https://api.deepseek.com\")\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "        #    {\"role\": \"system\", \"content\": full_user_prompt},\n",
    "            {\"role\": \"user\", \"content\": output_require_prompt},\n",
    "            {\"role\": \"assistant\", \"content\": history_snippet_prompt},\n",
    "            {\"role\": \"assistant\", \"content\": fail_reflections_prompt},\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        max_tokens=2048,\n",
    "        stream=False,\n",
    "        )\n",
    "    \n",
    "        raw_text = response.choices[0].message.content.strip()\n",
    "        func_code = extract_pure_code(raw_text)\n",
    "\n",
    "    elif args.LLM_type == 'Llama':\n",
    "        client = Together(api_key=LLAMA_API_KEY)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"meta-llama/Llama-4-Scout-17B-16E-Instruct\",  # Can be replaced with other Llama versions\n",
    "            messages=[\n",
    "        #    {\"role\": \"system\", \"content\": full_user_prompt},\n",
    "            {\"role\": \"user\", \"content\": output_require_prompt},\n",
    "            {\"role\": \"assistant\", \"content\": history_snippet_prompt},\n",
    "            {\"role\": \"assistant\", \"content\": fail_reflections_prompt},\n",
    "        ],\n",
    "        temperature=0.1,\n",
    "        max_tokens=2048,\n",
    "        )\n",
    "        raw_text = response.choices[0].message.content.strip()\n",
    "        func_code = extract_pure_code(raw_text)\n",
    "        \n",
    "\n",
    "    if selected_flag == 'org':\n",
    "        load_org_nor = train_load_data.scaler_y.transform(np.array(data_for_inqure['load']).reshape(-1,1)).flatten()\n",
    "        if isinstance(train_load_data.scaler_y, StandardScaler):\n",
    "            load_org_var_nor = data_for_inqure['pred_var']*train_load_data.scaler_y.scale_\n",
    "        elif isinstance(train_load_data.scaler_y, MinMaxScaler):\n",
    "            load_org_var_nor = data_for_inqure['pred_var']*(train_load_data.scaler_y.data_max_-train_load_data.scaler_y.data_min_)\n",
    "        \n",
    "        selected_curve, selected_var, delta_curve, strategy_code = execute_strategy_function(\n",
    "            func_code,\n",
    "            load_org_nor,\n",
    "            load_org_var_nor,\n",
    "            max_change_percent=0.1\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        fine_tuned_load_nor = train_load_data.scaler_y.transform(np.array(data_for_inqure['fine_tuned_load']).reshape(-1,1)).flatten()\n",
    "        # if isinstance(train_load_data.scaler_y, StandardScaler):\n",
    "        #    fine_tuned_load_var_nor= data_for_inqure['fine_tuned_var']*train_load_data.scaler_y.scale_\n",
    "        # elif isinstance(train_load_data.scaler_y, MinMaxScaler):\n",
    "        #    fine_tuned_load_var_nor= data_for_inqure['fine_tuned_var']*(train_load_data.scaler_y.data_max_-train_load_data.scaler_y.data_min_)\n",
    "        selected_curve, selected_var, delta_curve, strategy_code = execute_strategy_function(\n",
    "            func_code,\n",
    "            fine_tuned_load_nor,\n",
    "            data_for_inqure['fine_tuned_var'],\n",
    "            max_change_percent=0.1\n",
    "        )\n",
    "    # print(selected_curve,fine_tuned_load_nor)\n",
    "    fine_tune_load_numpy = train_load_data.scaler_y.inverse_transform(np.array(selected_curve).reshape(1, -1))[0]\n",
    "    # if isinstance(train_load_data.scaler_y, StandardScaler):\n",
    "    #     fine_tune_var_numpy = np.array(selected_var).flatten()*train_load_data.scaler_y.scale_\n",
    "    # elif isinstance(train_load_data.scaler_y, MinMaxScaler):\n",
    "    #     fine_tune_var_numpy = np.array(selected_var).flatten()*(train_load_data.scaler_y.data_max_-train_load_data.scaler_y.data_min_)\n",
    "    # print(selected_var,fine_tune_var_numpy)\n",
    "    _, _, obj_org = optimization_module.forward(load_numpy_mu_org, load_numpy_var_org, actual_load_numpy)\n",
    "    _, _, obj_optnet = optimization_module.forward(load_numpy_mu_optnet, load_numpy_var_optnet, actual_load_numpy)\n",
    "    # print(fine_tune_load_numpy,selected_var)\n",
    "    # print(load_numpy_mu_optnet,fine_tune_load_numpy)\n",
    "    _, _, obj_fine_tune = optimization_module.forward(fine_tune_load_numpy, selected_var, actual_load_numpy)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for i in valid_strategies:\n",
    "        plt.plot(i['adjusted_curve'], label=i['name'], linestyle='--', alpha=0.8)\n",
    "    if selected_flag == 'org':\n",
    "        plt.plot(range(24), i['original_load'], markersize=8, marker='o', label='Original Load', color='blue')\n",
    "    else:\n",
    "        plt.plot(range(24), i['original_load'], markersize=8, marker='o', label='Optnet Load', color='green')\n",
    "    plt.plot(range(24), i['actual_load'], markersize=8, marker='o', label='Actual Load', color='orange')\n",
    "    # plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    if selected_flag == 'org':\n",
    "        plt.plot(range(24), data_for_inqure['load'], label='Original Forecast Load(selected)', marker='o', color='blue')\n",
    "        plt.plot(range(24), data_for_inqure['fine_tuned_load'], label='Optnet Forecast Load', marker='o', color='green')\n",
    "    else:\n",
    "        plt.plot(range(24), data_for_inqure['fine_tuned_load'], label='Optnet Forecast Load(selected)', marker='o', color='green')\n",
    "        plt.plot(range(24), data_for_inqure['load'], label='Original Forecast Load', marker='o', color='blue')\n",
    "    plt.plot(range(24), actual_load_test_insert[inqure_id], label='Actual Load', marker='o', color='orange')\n",
    "    plt.plot(range(24), fine_tune_load_numpy, label='Fine-tuned Load', marker='o')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(f\"Original cost: {obj_org.item()}, Optnet cost: {obj_optnet.item()}, Fine-tuned cost: {obj_fine_tune.item()}\")\n",
    "\n",
    "    reflection_strategy = \"\"\n",
    "    if selected_flag == 'org' and obj_fine_tune.item() < obj_org.item():\n",
    "            reflection_strategy = \"Cost reduction achieved.\"\n",
    "            insight = f\"Successfully reduced cost by {obj_org.item() - obj_fine_tune.item():.2f}.\"\n",
    "    elif selected_flag == 'org' and obj_fine_tune.item() > obj_org.item():\n",
    "        failures = [{\"inqure_id\": inqure_id,\n",
    "            \"load\": data_for_inqure['load'],\n",
    "            \"actual_load\": actual_load_test_insert[inqure_id],\n",
    "            'fine_tuned_load': selected_curve,\n",
    "            \"cost_before\": obj_org.item(),\n",
    "            \"cost_after\": obj_fine_tune.item(),\n",
    "            \"strategy_code\": strategy_code,\n",
    "        }]\n",
    "\n",
    "        reflection_strategy_history, reflection_valid_strategies = few_shot_prompt_generate(args, failures, max_strategies=5, max_attempts=3)\n",
    "        reflection_strategy = f\"For this failure cases, consider:\"\n",
    "        for i in range(len(reflection_valid_strategies)):\n",
    "            strategy = reflection_valid_strategies[i]\n",
    "            reflection_strategy += f\"Success strategy {i} for failure case:\\n{remove_comments(strategy['code'])}\\n\"\n",
    "\n",
    "    if selected_flag == 'optnet' and obj_fine_tune.item() < obj_optnet.item():\n",
    "            reflection_strategy = \"Cost reduction achieved.\"\n",
    "            insight = f\"Successfully reduced cost by {obj_optnet.item() - obj_fine_tune.item():.2f}.\"\n",
    "    elif selected_flag == 'optnet' and obj_fine_tune.item() > obj_optnet.item():\n",
    "        failures = [{\"inqure_id\": inqure_id,\n",
    "            \"load\": data_for_inqure['load'],\n",
    "            'pred_var': data_for_inqure['pred_var'],\n",
    "            \"actual_load\": actual_load_test_insert[inqure_id],\n",
    "            'fine_tuned_load': selected_curve,\n",
    "            'fine_tuned_var': data_for_inqure['fine_tuned_var'],\n",
    "            \"cost_before\": obj_optnet.item(),\n",
    "            \"cost_after\": obj_fine_tune.item(),\n",
    "            \"strategy_code\": strategy_code,\n",
    "        }]\n",
    "\n",
    "        reflection_strategy_history, reflection_valid_strategies = few_shot_prompt_generate(args, failures, max_strategies=5, max_attempts=3,failure_strategy=strategy_code)\n",
    "        reflection_strategy = f\"For this failure cases, consider:\"\n",
    "        for i in range(len(reflection_valid_strategies)):\n",
    "            strategy = reflection_valid_strategies[i]\n",
    "            reflection_strategy += f\"Success strategy {i} for failure case:\\n{remove_comments(strategy['code'])}\\n\"\n",
    "\n",
    "    reflection_records.append({\n",
    "        \"inquiry_id\": inqure_id,\n",
    "        \"original_load\": data_for_inqure['load'],\n",
    "        \"actual_load\": actual_load_test_insert[inqure_id],\n",
    "        \"fine_tuned_load\": data_for_inqure['fine_tuned_load'],\n",
    "        \"cost_before\": obj_org.item(),\n",
    "        \"cost_after\": obj_fine_tune.item(),\n",
    "        \"strategy_code\": strategy_code,\n",
    "        \"reflection_strategy\": reflection_strategy,\n",
    "        \"similar_day_comparison\": f\"Similar days showed forecast was {higher_flag} than actual\"\n",
    "    })\n",
    "    reflection_records = reflection_records[-10:]  # Keep only the last 10 records\n",
    "\n",
    "    fine_tuned_result_given_by_LLM['selected_flag'].append(selected_flag)\n",
    "    fine_tuned_result_given_by_LLM['actual_load'].append(actual_load_test_insert[inqure_id])\n",
    "    fine_tuned_result_given_by_LLM['original_mu'].append(data_for_inqure['load'])\n",
    "    fine_tuned_result_given_by_LLM['optnet_mu'].append(data_for_inqure['fine_tuned_load'])\n",
    "    fine_tuned_result_given_by_LLM['fine_tuned_mu'].append(fine_tune_load_numpy)\n",
    "    fine_tuned_result_given_by_LLM['original_var'].append(data_for_inqure['pred_var'])\n",
    "    fine_tuned_result_given_by_LLM['optnet_var'].append(data_for_inqure['fine_tuned_var'])\n",
    "    fine_tuned_result_given_by_LLM['fine_tuned_var'].append(selected_var)\n",
    "    fine_tuned_result_given_by_LLM['cost_after'].append(obj_fine_tune.item())\n",
    "    fine_tuned_result_given_by_LLM['cost_org'].append(obj_org.item())\n",
    "    fine_tuned_result_given_by_LLM['cost_optnet'].append(obj_optnet.item())\n",
    "\n",
    "    fine_tuned_result_given_by_LLM['similar_mu'].append(average_similar_mu_org.tolist())\n",
    "    fine_tuned_result_given_by_LLM['similar_var'].append(average_similar_var_org.tolist())\n",
    "    fine_tuned_result_given_by_LLM['similar_actual_load'].append(average_similar_load_actual.tolist())\n",
    "    fine_tuned_result_given_by_LLM['few_shot_costs'].append(few_shot_costs)\n",
    "    fine_tuned_result_given_by_LLM['few_shot_curves'].append(few_shot_curves)\n",
    "    fine_tuned_result_given_by_LLM['few_shot_code'].append(few_shot_codes)\n",
    "    fine_tuned_result_given_by_LLM['strategy_code'].append(strategy_code)\n",
    "\n",
    "    if len(fine_tuned_result_given_by_LLM['cost_org']) > 1:\n",
    "        print(np.mean(fine_tuned_result_given_by_LLM['cost_org']))\n",
    "        print(np.mean(fine_tuned_result_given_by_LLM['cost_optnet']))\n",
    "        print(np.mean(fine_tuned_result_given_by_LLM['cost_after']))\n",
    "        plt.figure(figsize=(10, 3))\n",
    "        plt.plot(\n",
    "            range(len(fine_tuned_result_given_by_LLM['cost_org'])),\n",
    "            np.array(fine_tuned_result_given_by_LLM['cost_optnet']) - np.array(fine_tuned_result_given_by_LLM['cost_after']),\n",
    "            label='Compared to optnet'\n",
    "        )\n",
    "        plt.plot(\n",
    "            range(len(fine_tuned_result_given_by_LLM['cost_org'])),\n",
    "            np.array(fine_tuned_result_given_by_LLM['cost_org']) - np.array(fine_tuned_result_given_by_LLM['cost_after']),\n",
    "            label='Compared to original'\n",
    "        )\n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"The following samples (inquire_id) did not complete LLM fine-tuning; original forecast curves were used: {skip_samples}\")\n",
    "    print(f\"The following samples (inquire_id) failed to find effective strategies on validation set; original forecast curves were used: {validate_failures}\")\n",
    "\n",
    "    with open('../Result/NN+SO/'+args.LLM_type+'.pkl', 'wb') as f:\n",
    "        pickle.dump(fine_tuned_result_given_by_LLM, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40d450",
   "metadata": {},
   "source": [
    "### result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69bf9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3002.078768588654\n",
      "2960.2249544329475\n",
      "2953.1927266139833\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(fine_tuned_result_given_by_LLM['cost_org']))\n",
    "print(np.mean(fine_tuned_result_given_by_LLM['cost_optnet']))\n",
    "print(np.mean(fine_tuned_result_given_by_LLM['cost_after']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
